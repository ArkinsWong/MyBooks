<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>统计学习方法</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<p id="filepos179939" class="calibre_"><span class="calibre1"><span class="bold">第4章　朴素贝叶斯法</span></span></p><p class="calibre_13">朴素贝叶斯（naïve Bayes）法是基于贝叶斯定理与特征条件独立假设的分类方法<sup class="calibre5"><small id="filepos180178" class="calibre6"><a href="#filepos196841"><span class="calibre7">[1]</span></a></small></sup>。对于给定的训练数据集，首先基于特征条件独立假设学习输入/输出的联合概率分布；然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。朴素贝叶斯法实现简单，学习与预测的效率都很高，是一种常用的方法。</p><p class="calibre_8">本章叙述朴素贝叶斯法，包括朴素贝叶斯法的学习与分类、朴素贝叶斯法的参数估计算法。</p><p id="filepos180721" class="calibre_6"><span class="calibre9"><span class="bold">4.1　朴素贝叶斯法的学习与分类</span></span></p><p id="filepos180839" class="calibre_6"><span class="calibre2"><span class="bold">4.1.1　基本方法</span></span></p><p class="calibre_7">设输入空间x⊆R<sup class="calibre5"><small class="calibre6"><span class="calibre7">n</span></small></sup>为n维向量的集合，输出空间为类标记集合<img src="images/00940.jpg" class="calibre_29"/>＝{c<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，c<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,c<sub class="calibre8"><small class="calibre6"><span class="calibre7">K</span></small></sub>}。输入为特征向量x∊x，输出为类标记（class label）y∊<img src="images/00940.jpg" class="calibre_29"/>。X是定义在输入空间x上的随机向量，Y是定义在输出空间<img src="images/00940.jpg" class="calibre_29"/>上的随机变量。P(X,Y)是X和Y的联合概率分布。训练数据集</p><p class="calibre_20"><img src="images/00910.jpg" class="calibre_183"/></p><p class="calibre_22">由P(X,Y)独立同分布产生。</p><p class="calibre_8">朴素贝叶斯法通过训练数据集学习联合概率分布P(X,Y)。具体地，学习以下先验概率分布及条件概率分布。先验概率分布</p><p class="calibre_20"><img src="images/00932.jpg" class="calibre_38"/></p><p class="calibre_22">条件概率分布</p><p class="calibre_20"><img src="images/00333.jpg" class="calibre_184"/></p><p class="calibre_22">于是学习到联合概率分布P(X,Y)。</p><p class="calibre_8">条件概率分布P(X＝x|Y＝c<sub class="calibre8"><small class="calibre6"><span class="calibre7">k</span></small></sub>)有指数级数量的参数，其估计实际是不可行的。事实上，假设x<sup class="calibre5"><small class="calibre6"><span class="calibre7">(j)</span></small></sup>可取值有S<sub class="calibre8"><small class="calibre6"><span class="calibre7">j</span></small></sub>个，j＝1,2,…,n，Y可取值有K个，那么参数个数为<img src="images/00978.jpg" class="calibre_185"/>。</p><p class="calibre_8">朴素贝叶斯法对条件概率分布作了条件独立性的假设。由于这是一个较强的假设，朴素贝叶斯法也由此得名。具体地，条件独立性假设是</p><p class="calibre_20"><img src="images/00341.jpg" class="calibre_186"/></p><p class="calibre_24">朴素贝叶斯法实际上学习到生成数据的机制，所以属于生成模型。条件独立假设等于是说用于分类的特征在类确定的条件下都是条件独立的。这一假设使朴素贝叶斯法变得简单，但有时会牺牲一定的分类准确率。</p><p class="calibre_8">朴素贝叶斯法分类时，对给定的输入x，通过学习到的模型计算后验概率分布P(Y＝c<sub class="calibre8"><small class="calibre6"><span class="calibre7">k</span></small></sub>|X＝x)，将后验概率最大的类作为x的类输出。后验概率计算根据贝叶斯定理进行：</p><p class="calibre_20"><img src="images/01019.jpg" class="calibre_187"/></p><p class="calibre_22">将式（4.3）代入式（4.4）有</p><p class="calibre_20"><img src="images/00347.jpg" class="calibre_188"/></p><p class="calibre_22">这是朴素贝叶斯法分类的基本公式。于是，朴素贝叶斯分类器可表示为</p><p class="calibre_20"><img src="images/01068.jpg" class="calibre_189"/></p><p class="calibre_22">注意到，在式（4.6）中分母对所有C<sub class="calibre8"><small class="calibre6"><span class="calibre7">k</span></small></sub>都是相同的，所以，</p><p class="calibre_20"><img src="images/00016.jpg" class="calibre_190"/></p><p id="filepos184582" class="calibre_6"><span class="calibre2"><span class="bold">4.1.2　后验概率最大化的含义</span></span></p><p class="calibre_7">朴素贝叶斯法将实例分到后验概率最大的类中。这等价于期望风险最小化。假设选择0-1损失函数：</p><p class="calibre_20"><img src="images/00040.jpg" class="calibre_191"/></p><p class="calibre_22">式中f(X)是分类决策函数。这时，期望风险函数为</p><p class="calibre_20"><img src="images/00061.jpg" class="calibre_192"/></p><p class="calibre_22">期望是对联合分布P(X,Y)取的。由此取条件期望</p><p class="calibre_20"><img src="images/00368.jpg" class="calibre_193"/></p><p class="calibre_22">为了使期望风险最小化，只需对Xx＝逐个极小化，由此得到：</p><p class="calibre_20"><img src="images/00104.jpg" class="calibre_194"/></p><p class="calibre_22">这样一来，根据期望风险最小化准则就得到了后验概率最大化准则：</p><p class="calibre_20"><img src="images/00125.jpg" class="calibre_195"/></p><p class="calibre_22">即朴素贝叶斯法所采用的原理。</p><p id="filepos185934" class="calibre_6"><span class="calibre9"><span class="bold">4.2　朴素贝叶斯法的参数估计</span></span></p><p id="filepos186049" class="calibre_6"><span class="calibre2"><span class="bold">4.2.1　极大似然估计</span></span></p><p class="calibre_7">在朴素贝叶斯法中，学习意味着估计P(Y＝c<sub class="calibre8"><small class="calibre6"><span class="calibre7">k</span></small></sub>)和P(X<sup class="calibre5"><small class="calibre6"><span class="calibre7">(j)</span></small></sup>＝x<sup class="calibre5"><small class="calibre6"><span class="calibre7">(j)</span></small></sup>|Y＝c<sub class="calibre8"><small class="calibre6"><span class="calibre7">k</span></small></sub>)。可以应用极大似然估计法估计相应的概率。先验概率P(Y＝c<sub class="calibre8"><small class="calibre6"><span class="calibre7">k</span></small></sub>)的极大似然估计是</p><p class="calibre_20"><img src="images/00377.jpg" class="calibre_196"/></p><p class="calibre_22">设第j个特征x<sup class="calibre5"><small class="calibre6"><span class="calibre7">(j)</span></small></sup>可能取值的集合为{a<sub class="calibre8"><small class="calibre6"><span class="calibre7">j1</span></small></sub>,a<sub class="calibre8"><small class="calibre6"><span class="calibre7">j2</span></small></sub>,…,a<sub class="calibre8"><small class="calibre6"><span class="calibre7">jS</span></small></sub><sub class="calibre8"><small class="calibre6"><span class="calibre7">j</span></small></sub>}，条件概率P(x<sup class="calibre5"><small class="calibre6"><span class="calibre7">(j)</span></small></sup>＝a<sub class="calibre8"><small class="calibre6"><span class="calibre7">jl</span></small></sub>|Y＝c<sub class="calibre8"><small class="calibre6"><span class="calibre7">k</span></small></sub>)的极大似然估计是</p><p class="calibre_20"><img src="images/00380.jpg" class="calibre_197"/></p><p class="calibre_22">式中，<img src="images/00188.jpg" class="calibre_198"/>是第i个样本的第j个特征；a<sub class="calibre8"><small class="calibre6"><span class="calibre7">jl</span></small></sub>是第j个特征可能取的第l个值；I为指示函数。</p><p id="filepos187632" class="calibre_6"><span class="calibre2"><span class="bold">4.2.2　学习与分类算法</span></span></p><p class="calibre_7">下面给出朴素贝叶斯法的学习与分类算法。</p><p class="calibre_146"><span class="bold">算法4.1（朴素贝叶斯算法（naïve Bayes algorithm））</span></p><p class="calibre_146">输入：训练数据T＝{(x<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，y<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>),(x<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,y<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>),…,(x<sub class="calibre8"><small class="calibre6"><span class="calibre7">N</span></small></sub>,y<sub class="calibre8"><small class="calibre6"><span class="calibre7">N</span></small></sub>)}，其中<img src="images/00214.jpg" class="calibre_91"/>，<img src="images/00188.jpg" class="calibre_198"/>是第i个样本的第j个特征，<img src="images/00188.jpg" class="calibre_198"/>∊{a<sub class="calibre8"><small class="calibre6"><span class="calibre7">j1</span></small></sub>,a<sub class="calibre8"><small class="calibre6"><span class="calibre7">j2</span></small></sub>,…,a<sub class="calibre8"><small class="calibre6"><span class="calibre7">jS<sub class="calibre12"><small class="calibre13"><span class="calibre13">j</span></small></sub></span></small></sub>}，a<sub class="calibre8"><small class="calibre6"><span class="calibre7">jl</span></small></sub>是第j个特征可能取的第l个值，j＝1,2,…,n，l＝1,2,…,S<sub class="calibre8"><small class="calibre6"><span class="calibre7">j</span></small></sub>，y<sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>∊{c<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，c<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,c<sub class="calibre8"><small class="calibre6"><span class="calibre7">K</span></small></sub>}；实例x；</p><p class="calibre_8">输出：实例x的分类。</p><p class="calibre_8">（1）计算先验概率及条件概率</p><p class="calibre_20"><img src="images/00235.jpg" class="calibre_199"/></p><p class="calibre_24">（2）对于给定的实例x＝(x<sup class="calibre5"><small class="calibre6"><span class="calibre7">(1)</span></small></sup>,x<sup class="calibre5"><small class="calibre6"><span class="calibre7">(2)</span></small></sup>,…,x<sup class="calibre5"><small class="calibre6"><span class="calibre7">(n)</span></small></sup>)<sup class="calibre5"><small class="calibre6"><span class="calibre7">T</span></small></sup>，计算</p><p class="calibre_20"><img src="images/00256.jpg" class="calibre_200"/></p><p class="calibre_24">（3）确定实例x的类</p><p class="calibre_20"><img src="images/00005.jpg" class="calibre_201"/></p><p class="calibre_24"><span class="bold">例4.1</span>　试由表4.1的训练数据学习一个朴素贝叶斯分类器并确定x＝(2,S)<sup class="calibre5"><small class="calibre6"><span class="calibre7">T</span></small></sup>的类标记y。表中X<sup class="calibre5"><small class="calibre6"><span class="calibre7">(1)</span></small></sup>，X<sup class="calibre5"><small class="calibre6"><span class="calibre7">(2)</span></small></sup>为特征，取值的集合分别为A<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>＝{1,2,3}，A<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>＝{S，M,L}，Y为类标记，Y∊C＝{1,-1}。</p><p class="calibre_20"><span class="calibre2"><span class="bold">表4.1　训练数据</span></span></p><p class="calibre_20"><img src="images/00009.jpg" class="calibre_202"/></p><p class="calibre_24"><span class="bold">解</span>　根据算法4.1，由表4.1，容易计算下列概率：</p><p class="calibre_20"><img src="images/00011.jpg" class="calibre_203"/></p><p class="calibre_22">对于给定的x＝(2,S)<sup class="calibre5"><small class="calibre6"><span class="calibre7">T</span></small></sup>计算：</p><p class="calibre_20"><img src="images/00014.jpg" class="calibre_204"/></p><p class="calibre_24">因为P(Y＝-1)P(X<sup class="calibre5"><small class="calibre6"><span class="calibre7">(1)</span></small></sup>＝2|Y＝-1)P(X<sup class="calibre5"><small class="calibre6"><span class="calibre7">(2)</span></small></sup>＝S|Y＝-1)最大，所以y＝-1。</p><p id="filepos191362" class="calibre_6"><span class="calibre2"><span class="bold">4.2.3　贝叶斯估计</span></span></p><p class="calibre_7">用极大似然估计可能会出现所要估计的概率值为0的情况。这时会影响到后验概率的计算结果，使分类产生偏差。解决这一问题的方法是采用贝叶斯估计。具体地，条件概率的贝叶斯估计是</p><p class="calibre_20"><img src="images/00018.jpg" class="calibre_205"/></p><p class="calibre_22">式中<img src="images/00759.jpg" class="calibre_47"/>≥0。等价于在随机变量各个取值的频数上赋予一个正数<img src="images/00759.jpg" class="calibre_47"/>&gt;0。当<img src="images/00759.jpg" class="calibre_47"/>＝0时就是极大似然估计。常取<img src="images/00759.jpg" class="calibre_47"/>＝1，这时称为拉普拉斯平滑（Laplace smoothing）。显然，对任何l＝1,2,…,S<sub class="calibre8"><small class="calibre6"><span class="calibre7">j</span></small></sub>，K＝1,2,…,K，有</p><p class="calibre_20"><img src="images/00023.jpg" class="calibre_206"/></p><p class="calibre_22">表明式（4.10）确为一种概率分布。同样，先验概率的贝叶斯估计是</p><p class="calibre_20"><img src="images/00028.jpg" class="calibre_207"/></p><p class="calibre_24"><span class="bold">例4.2</span>　问题同例4.1，按照拉普拉斯平滑估计概率，即取<img src="images/00759.jpg" class="calibre_47"/>＝1。</p><p class="calibre_8"><span class="bold">解</span>　A<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>＝{1,2,3}，A<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>＝{S,M,L}，C＝{1,-1}。按照式（4.10）和式（4.11）计算下列概率：</p><p class="calibre_20"><img src="images/00031.jpg" class="calibre_208"/></p><p class="calibre_22">对于给定的x＝(2,S)<sup class="calibre5"><small class="calibre6"><span class="calibre7">T</span></small></sup>计算：</p><p class="calibre_20"><img src="images/00034.jpg" class="calibre_209"/></p><p class="calibre_22">由于P(Y＝-1)P(X<sup class="calibre5"><small class="calibre6"><span class="calibre7">(1)</span></small></sup>＝2|Y＝-1)P(X<sup class="calibre5"><small class="calibre6"><span class="calibre7">(2)</span></small></sup>＝S|Y＝-1)最大，所以y＝-1。</p><p id="filepos193775" class="calibre_6"><span class="calibre9"><span class="bold">本章概要</span></span></p><p class="calibre_7">1．朴素贝叶斯法是典型的生成学习方法。生成方法由训练数据学习联合概率分布P(X,Y)，然后求得后验概率分布P(Y|X)。具体来说，利用训练数据学习P(X|Y)和P(Y)的估计，得到联合概率分布：</p><p class="calibre_33">P(X,Y)＝P(Y)P(X|Y)</p><p class="calibre_9">概率估计方法可以是极大似然估计或贝叶斯估计：</p><p class="calibre_8">2．朴素贝叶斯法的基本假设是条件独立性，</p><p class="calibre_20"><img src="images/00038.jpg" class="calibre_210"/></p><p class="calibre_22">这是一个较强的假设。由于这一假设，模型包含的条件概率的数量大为减少，朴素贝叶斯法的学习与预测大为简化。因而朴素贝叶斯法高效，且易于实现。其缺点是分类的性能不一定很高。</p><p class="calibre_8">3．朴素贝叶斯法利用贝叶斯定理与学到的联合概率模型进行分类预测。</p><p class="calibre_20"><img src="images/00041.jpg" class="calibre_211"/></p><p class="calibre_22">将输入x分到后验概率最大的类y。</p><p class="calibre_20"><img src="images/00045.jpg" class="calibre_212"/></p><p class="calibre_22">后验概率最大等价于0-1损失函数时的期望风险最小化。</p><p id="filepos195329" class="calibre_6"><span class="calibre9"><span class="bold">继续阅读</span></span></p><p class="calibre_7">朴素贝叶斯法的介绍可见文献[1,2]。朴素贝叶斯法中假设输入变量都是条件独立的，如果假设它们之间存在概率依存关系，模型就变成了贝叶斯网络，参见文献[3]。</p><p id="filepos195664" class="calibre_6"><span class="calibre9"><span class="bold">习题</span></span></p><p class="calibre_7">4.1　用极大似然估计法推出朴素贝叶斯法中的概率估计公式（4.8）及公式（4.9）。</p><p class="calibre_8">4.2　用贝叶斯估计法推出朴素贝叶斯法中的概率估计公式（4.10）及公式（4.11）。</p><p id="filepos196025" class="calibre_6"><span class="calibre9"><span class="bold">参考文献</span></span></p><p class="calibre_7">[1]　Mitchell TM. Chapter 1: Generative and discriminative classifiers: Naïve Bayes and logistic regression. In: Machine Learning. Draft,2005. http://www.cs.cmu.edu/~tom/mlbook/NBayeslogReg.pdf</p><p class="calibre_8">[2]　Hastie T,Tibshirani R,Friedman J. The Elements of Statistical Learning. Data Mining,Inference,and Prediction. Springer-Verlag,2001（中译本：统计学习基础——数据挖掘、推理与预测。范明，柴玉梅，昝红英等译。北京：电子工业出版社，2004）</p><p class="calibre_8">[3]　Bishop C. Pattern Recognition and Machine Learning,Springer,2006</p><p class="calibre_98"><span class="calibre2"><span class="bold">注释</span></span></p><p id="filepos196841" class="calibre_99"><a href="#filepos180178"><span class="calibre4">[1]</span></a><span class="calibre4">　注意：朴素贝叶斯法与贝叶斯估计（Bayesian estimation）是不同的概念。</span></p><div class="mbp_pagebreak" id="calibre_pb_9"></div>
</body></html>
