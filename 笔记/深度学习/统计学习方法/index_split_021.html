<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>统计学习方法</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<p id="filepos732946" class="calibre_"><span class="calibre1"><span class="bold">索引</span></span></p><p class="calibre_13">奥卡姆剃刀（Occam's razor）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">半监督学习（semi-supervised learning）</p><p class="calibre_8">贝叶斯估计（Bayesian estimation）</p><p class="calibre_8">比特（bit）</p><p class="calibre_8">边（edge）</p><p class="calibre_8">标注（tagging）</p><p class="calibre_8">不完全数据（incomplete-data）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">参数空间（parameter space）</p><p class="calibre_8">残差（residual）</p><p class="calibre_8">测试集（test set）</p><p class="calibre_8">测试数据（test data）</p><p class="calibre_8">测试误差（test error）</p><p class="calibre_8">策略（strategy）</p><p class="calibre_8">成对马尔可夫性（pairwise Markov property）</p><p class="calibre_8">词性标注（part of speech tagging）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">代价函数（cost function）</p><p class="calibre_8">代理损失函数（surrogate loss function）</p><p class="calibre_8">带符号的距离（signed distance）</p><p class="calibre_8">单元（cell）</p><p class="calibre_8">动态规划（dynamic programming）</p><p class="calibre_8">对偶算法（dual algorithm）</p><p class="calibre_8">对偶问题（dual problem）</p><p class="calibre_8">对数几率（log odds）</p><p class="calibre_8">对数似然损失函数（log-likelihood loss function）</p><p class="calibre_8">对数损失函数（logarithmic loss function）</p><p class="calibre_8">对数线性模型（log linear model）</p><p class="calibre_8">多数表决规则（majority voting rule）</p><p class="calibre_8">多项逻辑斯谛回归模型（multi-nominal logistic regression model）</p><p class="calibre_8">多项式核函数（polynomial kernel function）</p><p class="calibre_8">二项逻辑斯谛回归模型（binomial logistic regression model）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">罚项（penalty term）</p><p class="calibre_8">泛化能力（generalization ability）</p><p class="calibre_8">泛化误差（generalization error）</p><p class="calibre_8">泛化误差上界（generalization error bound）</p><p class="calibre_8">非监督学习（unsupervised learning）</p><p class="calibre_8">非线性支持向量机（non-linear support vector machine）</p><p class="calibre_8">分类（classification）</p><p class="calibre_8">分类器（classifier）</p><p class="calibre_8">分类与回归树（classification and regression tree，CART）</p><p class="calibre_8">分离超平面（separating hyperplane）</p><p class="calibre_8">风险函数（risk function）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">改进的迭代尺度法（improved iterative scaling，IIS）</p><p class="calibre_8">概率近似正确（probably approximately correct，PAC）</p><p class="calibre_8">概率图模型（probabilistic graphical model）</p><p class="calibre_8">概率无向图模型（probabilistic undirected graphical model）</p><p class="calibre_8">感知机（perceptron）</p><p class="calibre_8">高斯核函数（Gaussian kernel function）</p><p class="calibre_8">高斯混合模型（Gaussian mixture model）</p><p class="calibre_8">根结点（root node）</p><p class="calibre_8">估计误差（estimation error）</p><p class="calibre_8">观测变量（observable variable）</p><p class="calibre_8">观测序列（observation sequence）</p><p class="calibre_8">广义拉格朗日函数（generalized Lagrange function）</p><p class="calibre_8">广义期望极大（generalized expectation maximization，GEM）</p><p class="calibre_8">规范化因子（normalization factor）</p><p class="calibre_8">过拟合（over-fitting）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">海赛矩阵（Hesse matrix）</p><p class="calibre_8">函数间隔（functional margin）</p><p class="calibre_8">合页损失函数（hinge loss function）</p><p class="calibre_8">核方法（kernel method）</p><p class="calibre_8">核函数（kernel function）</p><p class="calibre_8">核技巧（kernel trick）</p><p class="calibre_8">互信息（mutual information）</p><p class="calibre_8">划分（partition）</p><p class="calibre_8">回归（regression）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">基尼指数（Gini index）</p><p class="calibre_8">极大-极大算法（maximization-maximization algorithm）</p><p class="calibre_8">极大似然估计（maximum likelihood estimation）</p><p class="calibre_8">几何间隔（geometric margin）</p><p class="calibre_8">几率（odds）</p><p class="calibre_8">加法模型（additive model）</p><p class="calibre_8">假设空间（hypothesis space）</p><p class="calibre_8">间隔（margin）</p><p class="calibre_8">监督学习（supervised learning）</p><p class="calibre_8">剪枝（pruning）</p><p class="calibre_8">交叉验证（cross validation）</p><p class="calibre_8">结点（node）</p><p class="calibre_8">结构风险最小化（structural risk minimization，SRM）</p><p class="calibre_8">解码（decoding）</p><p class="calibre_8">近似误差（approximation error）</p><p class="calibre_8">经验风险（empirical risk）</p><p class="calibre_8">经验风险最小化（empirical risk minimization，ERM）</p><p class="calibre_8">经验熵（empirical entropy）</p><p class="calibre_8">经验损失（empirical loss）</p><p class="calibre_8">经验条件熵（empirical conditional entropy）</p><p class="calibre_8">精确率（precision）</p><p class="calibre_8">径向基函数（radial basis function）</p><p class="calibre_8">局部马尔可夫性（local Markov property）</p><p class="calibre_8">决策函数（decision function）</p><p class="calibre_8">决策树（decision tree）</p><p class="calibre_8">决策树桩（decision stump）</p><p class="calibre_8">绝对损失函数（absolute loss function）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">拉格朗日乘子（Lagrange multiplier）</p><p class="calibre_8">拉格朗日对偶性（Lagrange duality）</p><p class="calibre_8">拉格朗日函数（Lagrange function）</p><p class="calibre_8">拉普拉斯平滑（Laplace smoothing）</p><p class="calibre_8">类（class）</p><p class="calibre_8">类标记（class label）</p><p class="calibre_8">留一交叉验证（leave-one-out cross validation）</p><p class="calibre_8">逻辑斯谛分布（logistic distribution）</p><p class="calibre_8">逻辑斯谛回归（logistic regression）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">马尔可夫随机场（Markov random field）</p><p class="calibre_8">曼哈顿距离（Manhattan distance）</p><p class="calibre_8">模型（model）</p><p class="calibre_8">模型选择（model selection）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">内部结点（internal node）</p><p class="calibre_8">纳特（nat）</p><p class="calibre_8">拟牛顿法（quasi Newton method）</p><p class="calibre_8">牛顿法（Newton method）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">欧氏距离（Euclidean distance）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">判别方法（discriminative approach）</p><p class="calibre_8">判别模型（discriminative model）</p><p class="calibre_8">偏置（bias）</p><p class="calibre_8">平方损失函数（quadratic loss function）</p><p class="calibre_8">评价准则（evaluation criterion）</p><p class="calibre_8">朴素贝叶斯（naïve Bayes）</p><p class="calibre_8">朴素贝叶斯算法（naïve Bayes algorithm）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">期望极大算法（EM算法）（expectation maximization algorithm）</p><p class="calibre_8">期望损失（expected loss）</p><p class="calibre_8">前向分步算法（forward stagewise algorithm）</p><p class="calibre_8">前向-后向算法（forward-backward algorithm）</p><p class="calibre_8">潜在变量（latent variable）</p><p class="calibre_8">强化学习（reinforcement learning）</p><p class="calibre_8">强可学习（strongly learnable）</p><p class="calibre_8">切分变量（splitting variable）</p><p class="calibre_8">切分点（splitting point）</p><p class="calibre_8">全局马尔可夫性（global Markov property）</p><p class="calibre_8">权值（weight）</p><p class="calibre_8">权值向量（weight vector）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">软间隔最大化（soft margin maximization）</p><p class="calibre_8">弱可学习（weakly learnable）</p><p class="calibre_8">熵（entropy）</p><p class="calibre_8">生成方法（generative approach）</p><p class="calibre_8">生成模型（generative model）</p><p class="calibre_8">实例（instance）</p><p class="calibre_8">势函数（potential function）</p><p class="calibre_8">输出空间（output space）</p><p class="calibre_8">输入空间（input space）</p><p class="calibre_8">数据（data）</p><p class="calibre_8">算法（algorithm）</p><p class="calibre_8">随机梯度下降法（stochastic gradient descent）</p><p class="calibre_8">损失函数（loss function）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">特异点（outlier）</p><p class="calibre_8">特征函数（feature function）</p><p class="calibre_8">特征空间（feature space）</p><p class="calibre_8">特征向量（feature vector）</p><p class="calibre_8">梯度提升（gradient boosting）</p><p class="calibre_8">梯度下降法（gradient descent）</p><p class="calibre_8">提升（boosting）</p><p class="calibre_8">提升树（boosting tree）</p><p class="calibre_8">提早停止（early stopping）</p><p class="calibre_8">条件熵（conditional entropy）</p><p class="calibre_8">条件随机场（conditional random field，CRF）</p><p class="calibre_8">统计机器学习（statistical machine learning）</p><p class="calibre_8">统计学习（statistical learning）</p><p class="calibre_8">统计学习方法（statistical learning method）</p><p class="calibre_8">统计学习理论（statistical learning theory）</p><p class="calibre_8">统计学习应用（application of statistical learning）</p><p class="calibre_8">凸二次规划（convex quadratic programming）</p><p class="calibre_8">图（graph）</p><p class="calibre_8">团（clique）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">完全数据（complete-data）</p><p class="calibre_8">维特比算法（Viterbi algorithm）</p><p class="calibre_8">文本分类（text classification）</p><p class="calibre_8">误差率（error rate）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">希尔伯特空间（Hilbert space）</p><p class="calibre_8">线性分类模型（linear classification model）</p><p class="calibre_8">线性分类器（linear classifier）</p><p class="calibre_8">线性可分数据集（linearly separable data set）</p><p class="calibre_8">线性可分支持向量机（linear support vector machine in linearly separable case）</p><p class="calibre_8">线性链（linear chain）</p><p class="calibre_8">线性链条件随机场（linear chain conditional random field）</p><p class="calibre_8">线性扫描（linear scan）</p><p class="calibre_8">线性支持向量机（linear support vector machine）</p><p class="calibre_8">信息增益（information gain）</p><p class="calibre_8">信息增益比（information gain ratio）</p><p class="calibre_8">序列最小最优化（sequential minimal optimization，SMO）</p><p class="calibre_8">学习率（learning rate）</p><p class="calibre_8">训练集（training set）</p><p class="calibre_8">训练数据（training data）</p><p class="calibre_8">训练误差（training error）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">验证集（validation set）</p><p class="calibre_8">叶结点（leaf node）</p><p class="calibre_8">因子分解（factorization）</p><p class="calibre_8">隐变量（hidden variable）</p><p class="calibre_8">隐马尔可夫模型（hidden Markov model,HMM）</p><p class="calibre_8">硬间隔最大化（hard margin maximization）</p><p class="calibre_8">有向边（directed edge）</p><p class="calibre_8">余弦相似度（cosine similarity）</p><p class="calibre_8">预测（prediction）</p><p class="calibre_8">原始问题（primal problem）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">再生核希尔伯特空间（reproducing kernel Hilbert space，RKHS）</p><p class="calibre_8">召回率（recall）</p><p class="calibre_8">正定核函数（positive definite kernel function）</p><p class="calibre_8">正则化（regularization）</p><p class="calibre_8">正则化项（regularizer）</p><p class="calibre_8">支持向量（support vector）</p><p class="calibre_8">支持向量机（support vector machines，SVM）</p><p class="calibre_8">指示函数（indicator function）</p><p class="calibre_8">指数损失函数（exponential loss function）</p><p class="calibre_8">中位数（median）</p><p class="calibre_8">状态序列（state sequence）</p><p class="calibre_8">准确率（accuracy）</p><p class="calibre_8">字符串核函数（string kernel function）</p><p class="calibre_8">最大后验概率估计（maximum posterior probability estimation，MAP）</p><p class="calibre_8">最大间隔法（maximum margin method）</p><p class="calibre_8">最大熵模型（maximum entropy model）</p><p class="calibre_8">最大团（maximal clique）</p><p class="calibre_8">最速下降法（steepest descent）</p><p class="calibre_8">最小二乘法（least squares）</p><p class="calibre_8">最小二乘回归树（least squares regression tree）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">0-1损失函数（0-1 loss function）</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">AdaBoost算法（AdaBoost algorithm）</p><p class="calibre_8">Baum-Welch算法（Baum-Welch algorithm）</p><p class="calibre_8">BFGS算法（Broyden-Fletcher-Goldfarb-Shanno algorithm,BFGS algorithm）</p><p class="calibre_8">Broyden类算法（Broyden's algorithm）</p><p class="calibre_8">C4.5算法（C4.5 algorithm）</p><p class="calibre_8">DFP算法（Davidon-Fletcher-Powell algorithm,DFP algorithm）</p><p class="calibre_8">EM算法（EM algorithm）</p><p class="calibre_8">F函数（F function）</p><p class="calibre_8">Gram矩阵（Gram matrix）</p><p class="calibre_8">ID3算法（ID3 algorithm）</p><p class="calibre_8">Jensen不等式（Jensen inequality）</p><p class="calibre_8">kd树（kd tree）</p><p class="calibre_8">KKT（Karush-Kuhn-Tucker）条件（KKT（Karush-Kuhn-Tucker）conditions）</p><p class="calibre_8">k近邻法（k-nearest neighbor，k-NN）</p><p class="calibre_8">L<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>范数（L<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub> norm）</p><p class="calibre_8">L<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>范数（L<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub> norm）</p><p class="calibre_8">L<sub class="calibre8"><small class="calibre6"><span class="calibre7">p</span></small></sub>距离（L<sub class="calibre8"><small class="calibre6"><span class="calibre7">p</span></small></sub> distance）</p><p class="calibre_8">Minkowski距离（Minkowski distance）</p><p class="calibre_8">Q函数（Q function）</p><p class="calibre_8">S形曲线（sigmoid curve）</p><p class="calibre_8">S折交叉验证（S-fold cross validation）</p><div class="mbp_pagebreak" id="calibre_pb_21"></div>
</body></html>
