<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>统计学习方法</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<p id="filepos565797" class="calibre_"><span class="calibre1"><span class="bold">第10章　隐马尔可夫模型</span></span></p><p class="calibre_13">隐马尔可夫模型（hidden Markov model,HMM）是可用于标注问题的统计学习模型，描述由隐藏的马尔可夫链随机生成观测序列的过程，属于生成模型。本章首先介绍隐马尔可夫模型的基本概念，然后分别叙述隐马尔可夫模型的概率计算算法、学习算法以及预测算法。隐马尔可夫模型在语音识别、自然语言处理、生物信息、模式识别等领域有着广泛的应用。</p><p id="filepos566398" class="calibre_6"><span class="calibre9"><span class="bold">10.1　隐马尔可夫模型的基本概念</span></span></p><p id="filepos566517" class="calibre_6"><span class="calibre2"><span class="bold">10.1.1　隐马尔可夫模型的定义</span></span></p><p class="calibre_7"><span class="bold">定义10.1（隐马尔可夫模型）</span>　隐马尔可夫模型是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程。隐藏的马尔可夫链随机生成的状态的序列，称为状态序列（state sequence）；每个状态生成一个观测，而由此产生的观测的随机序列，称为观测序列（observation sequence）。序列的每一个位置又可以看作是一个时刻。</p><p class="calibre_8">隐马尔可夫模型由初始概率分布、状态转移概率分布以及观测概率分布确定。隐马尔可夫模型的形式定义如下：</p><p class="calibre_8">设Q是所有可能的状态的集合，V是所有可能的观测的集合。</p><p class="calibre_20"><img src="images/00925.jpg" class="calibre_762"/></p><p class="calibre_22">其中，N是可能的状态数，M是可能的观测数。</p><p class="calibre_8">I是长度为T的状态序列，O是对应的观测序列。</p><p class="calibre_20"><img src="images/01033.jpg" class="calibre_763"/></p><p class="calibre_24">A是状态转移概率矩阵：</p><p class="calibre_20"><img src="images/00877.jpg" class="calibre_764"/></p><p class="calibre_22">其中，</p><p class="calibre_20"><img src="images/00354.jpg" class="calibre_765"/></p><p class="calibre_22">是在时刻t处于状态q<sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>的条件下在时刻t+1转移到状态q<sub class="calibre8"><small class="calibre6"><span class="calibre7">j</span></small></sub>的概率。</p><p class="calibre_8">B是观测概率矩阵：</p><p class="calibre_20"><img src="images/00645.jpg" class="calibre_766"/></p><p class="calibre_22">其中，</p><p class="calibre_20"><img src="images/00749.jpg" class="calibre_767"/></p><p class="calibre_22">是在时刻t处于状态q<sub class="calibre8"><small class="calibre6"><span class="calibre7">j</span></small></sub>的条件下生成观测v<sub class="calibre8"><small class="calibre6"><span class="calibre7">k</span></small></sub>的概率。</p><p class="calibre_8"><img src="images/01057.jpg" class="calibre_686"/>是初始状态概率向量：</p><p class="calibre_20"><img src="images/00512.jpg" class="calibre_768"/></p><p class="calibre_22">其中，</p><p class="calibre_20"><img src="images/00302.jpg" class="calibre_769"/></p><p class="calibre_22">是时刻t＝1处于状态q<sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>的概率。</p><p class="calibre3" style="margin:0pt; border:0pt; height:1em"> </p><p class="calibre_8">隐马尔可夫模型由初始状态概率向量<img src="images/01057.jpg" class="calibre_686"/>、状态转移概率矩阵A和观测概率矩阵B决定。<img src="images/01057.jpg" class="calibre_686"/>和A决定状态序列，B决定观测序列。因此，隐马尔可夫模型<img src="images/00759.jpg" class="calibre_47"/>可以用三元符号表示，即</p><p class="calibre_20"><img src="images/00683.jpg" class="calibre_770"/></p><p class="calibre_22">A,B,<img src="images/01057.jpg" class="calibre_686"/>称为隐马尔可夫模型的三要素。</p><p class="calibre_8">状态转移概率矩阵A与初始状态概率向量<img src="images/01057.jpg" class="calibre_686"/>确定了隐藏的马尔可夫链，生成不可观测的状态序列。观测概率矩阵B确定了如何从状态生成观测，与状态序列综合确定了如何产生观测序列。</p><p class="calibre_8">从定义可知，隐马尔可夫模型作了两个基本假设：</p><p class="calibre_8">（1）齐次马尔可夫性假设，即假设隐藏的马尔可夫链在任意时刻t的状态只依赖于其前一时刻的状态，与其他时刻的状态及观测无关，也与时刻t无关。</p><p class="calibre_20"><img src="images/00208.jpg" class="calibre_771"/></p><p class="calibre_24">（2）观测独立性假设，即假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关。</p><p class="calibre_20"><img src="images/00225.jpg" class="calibre_772"/></p><p class="calibre_24">隐马尔可夫模型可以用于标注，这时状态对应着标记。标注问题是给定观测的序列预测其对应的标记序列。可以假设标注问题的数据是由隐马尔可夫模型生成的。这样我们可以利用隐马尔可夫模型的学习与预测算法进行标注。</p><p class="calibre_8">下面看一个隐马尔可夫模型的例子。</p><p class="calibre_8"><span class="bold">例10.1（盒子和球模型）</span>　假设有4个盒子，每个盒子里都装有红白两种颜色的球，盒子里的红白球数由表10.1列出。</p><p class="calibre_20"><span class="calibre2"><span class="bold">表10.1　各盒子的红白球数</span></span></p><p class="calibre_20"><img src="images/00530.jpg" class="calibre_773"/></p><p class="calibre_24">按照下面的方法抽球，产生一个球的颜色的观测序列：开始，从4个盒子里以等概率随机选取1个盒子，从这个盒子里随机抽出1个球，记录其颜色后，放回；然后，从当前盒子随机转移到下一个盒子，规则是：如果当前盒子是盒子1，那么下一盒子一定是盒子2，如果当前是盒子2或3，那么分别以概率0.4和0.6转移到左边或右边的盒子，如果当前是盒子4，那么各以0.5的概率停留在盒子4或转移到盒子3；确定转移的盒子后，再从这个盒子里随机抽出1个球，记录其颜色，放回；如此下去，重复进行5次，得到一个球的颜色的观测序列：</p><p class="calibre_33">O＝{红,红,白,白,红}</p><p class="calibre_9">在这个过程中，观察者只能观测到球的颜色的序列，观测不到球是从哪个盒子取出的，即观测不到盒子的序列。</p><p class="calibre_8">在这个例子中有两个随机序列，一个是盒子的序列（状态序列），一个是球的颜色的观测序列（观测序列）。前者是隐藏的，只有后者是可观测的。这是一个隐马尔可夫模型的例子，根据所给条件，可以明确状态集合、观测集合、序列长度以及模型的三要素。</p><p class="calibre_8">盒子对应状态，状态的集合是</p><p class="calibre_33">Q＝{盒子1,盒子2,盒子3,盒子4}，N＝4</p><p class="calibre_8">球的颜色对应观测。观测的集合是</p><p class="calibre_33">V＝{红,白}，M＝2</p><p class="calibre_8">状态序列和观测序列长度T＝5。</p><p class="calibre_8">初始概率分布为</p><p class="calibre_33"><img src="images/01057.jpg" class="calibre_686"/>＝(0.25,0.25,0.25,0.25)<sup class="calibre5"><small class="calibre6"><span class="calibre7">T</span></small></sup></p><p class="calibre_8">状态转移概率分布为</p><p class="calibre_20"><img src="images/00441.jpg" class="calibre_774"/></p><p class="calibre_24">观测概率分布为</p><p class="calibre_20"><img src="images/00560.jpg" class="calibre_775"/></p><p id="filepos574428" class="calibre_6"><span class="calibre2"><span class="bold">10.1.2　观测序列的生成过程</span></span></p><p class="calibre_7">根据隐马尔可夫模型定义，可以将一个长度为T的观测序列O＝(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)的生成过程描述如下：</p><p class="calibre_146"><span class="bold">算法10.1（观测序列的生成）</span></p><p class="calibre_146">输入：隐马尔可夫模型<img src="images/00759.jpg" class="calibre_47"/>＝(A，B,<img src="images/01057.jpg" class="calibre_686"/>)，观测序列长度T；</p><p class="calibre_8">输出：观测序列O＝(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)。</p><p class="calibre_8">（1）按照初始状态分布<img src="images/01057.jpg" class="calibre_686"/>产生状态i<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub></p><p class="calibre_8">（2）令t＝1</p><p class="calibre_8">（3）按照状态i<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>的观测概率分布b<sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>t(k)生成o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub></p><p class="calibre_8">（4）按照状态i<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>的状态转移概率分布{<img src="images/00672.jpg" class="calibre_776"/>}产生状态i<sub class="calibre8"><small class="calibre6"><span class="calibre7">t+1</span></small></sub>，i<sub class="calibre8"><small class="calibre6"><span class="calibre7">t+1</span></small></sub>＝1,2,…,N</p><p class="calibre_8">（5）令t＝t+1；如果t&lt;T，转步（3）；否则，终止</p><p id="filepos576263" class="calibre_6"><span class="calibre2"><span class="bold">10.1.3　隐马尔可夫模型的3个基本问题</span></span></p><p class="calibre_7">隐马尔可夫模型有3个基本问题：</p><p class="calibre_8">（1）概率计算问题。给定模型<img src="images/00759.jpg" class="calibre_47"/>＝(A，B,<img src="images/01057.jpg" class="calibre_686"/>)和观测序列O＝(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)，计算在模型<img src="images/00759.jpg" class="calibre_47"/>下观测序列O出现的概率P(O|<img src="images/00759.jpg" class="calibre_47"/>)。</p><p class="calibre_8">（2）学习问题。已知观测序列O＝(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)，估计模型<img src="images/00759.jpg" class="calibre_47"/>＝(A，B,<img src="images/01057.jpg" class="calibre_686"/>)参数，使得在该模型下观测序列概率P(O|<img src="images/00759.jpg" class="calibre_47"/>)最大。即用极大似然估计的方法估计参数。</p><p class="calibre_8">（3）预测问题，也称为解码（decoding）问题。已知模型<img src="images/00759.jpg" class="calibre_47"/>＝(A，B,<img src="images/01057.jpg" class="calibre_686"/>)和观测序列O＝(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)，求对给定观测序列条件概率P(I|O)最大的状态序列I＝(i<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，i<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,i<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)。即给定观测序列，求最有可能的对应的状态序列。</p><p class="calibre_8">下面各节将逐一介绍这些基本问题的解法。</p><p id="filepos578430" class="calibre_6"><span class="calibre9"><span class="bold">10.2　概率计算算法</span></span></p><p class="calibre_7">本节介绍计算观测序列概率P(O|<img src="images/00759.jpg" class="calibre_47"/>)的前向（forward）与后向（backward）算法。先介绍概念上可行但计算上不可行的直接计算法。</p><p id="filepos578790" class="calibre_6"><span class="calibre2"><span class="bold">10.2.1　直接计算法</span></span></p><p class="calibre_7">给定模型<img src="images/00759.jpg" class="calibre_47"/>＝(A，B,<img src="images/01057.jpg" class="calibre_686"/>)和观测序列O＝(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)，计算观测序列O出现的概率P(O|<img src="images/00759.jpg" class="calibre_47"/>)。最直接的方法是按概率公式直接计算。通过列举所有可能的长度为T的状态序列I＝(i<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，i<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,i<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)，求各个状态序列I与观测序列O＝(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)的联合概率P(O，I|<img src="images/00759.jpg" class="calibre_47"/>)，然后对所有可能的状态序列求和，得到P(O|<img src="images/00759.jpg" class="calibre_47"/>)。</p><p class="calibre_8">状态序列I＝(i<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，i<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,i<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)的概率是</p><p class="calibre_20"><img src="images/00779.jpg" class="calibre_777"/></p><p class="calibre_24">对固定的状态序列I＝(i<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，i<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,i<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)，观测序列O＝(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)的概率是P(O|I,<img src="images/00759.jpg" class="calibre_47"/>)，</p><p class="calibre_20"><img src="images/00883.jpg" class="calibre_778"/></p><p class="calibre_24">O和I同时出现的联合概率为</p><p class="calibre_20"><img src="images/00994.jpg" class="calibre_779"/></p><p class="calibre_24">然后，对所有可能的状态序列I求和，得到观测序列O的概率P(O|<img src="images/00759.jpg" class="calibre_47"/>)，即</p><p class="calibre_20"><img src="images/00037.jpg" class="calibre_780"/></p><p class="calibre_24">但是，利用公式（10.13）计算量很大，是O(TN<sup class="calibre5"><small class="calibre6"><span class="calibre7">T</span></small></sup>)阶的，这种算法不可行。</p><p class="calibre_8">下面介绍计算观测序列概率P(O|<img src="images/00759.jpg" class="calibre_47"/>)的有效算法：前向-后向算法（forwardbackward algorithm）。</p><p id="filepos581862" class="calibre_6"><span class="calibre2"><span class="bold">10.2.2　前向算法</span></span></p><p class="calibre_7">首先定义前向概率。</p><p class="calibre_8"><span class="bold">定义10.2（前向概率）</span>　给定隐马尔可夫模型<img src="images/00759.jpg" class="calibre_47"/>，定义到时刻t部分观测序列为o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>且状态为q<sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>的概率为前向概率，记作</p><p class="calibre_20"><img src="images/00142.jpg" class="calibre_781"/></p><p class="calibre_24">可以递推地求得前向概率a<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>(i)及观测序列概率P(O|<img src="images/00759.jpg" class="calibre_47"/>)。</p><p class="calibre_146"><span class="bold">算法10.2（观测序列概率的前向算法）</span></p><p class="calibre_146">输入：隐马尔可夫模型<img src="images/00759.jpg" class="calibre_47"/>，观测序列O；</p><p class="calibre_8">输出：观测序列概率P(O|<img src="images/00759.jpg" class="calibre_47"/>)。</p><p class="calibre_8">（1）初值</p><p class="calibre_20"><img src="images/00253.jpg" class="calibre_782"/></p><p class="calibre_24">（2）递推　对t＝1,2,…，T-1，</p><p class="calibre_20"><img src="images/00364.jpg" class="calibre_783"/></p><p class="calibre_24">（3）终止</p><p class="calibre_20"><img src="images/00472.jpg" class="calibre_784"/></p><p class="calibre_24">前向算法，步骤（1）初始化前向概率，是初始时刻的状态i<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>＝q<sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>和观测o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>的联合概率。步骤（2）是前向概率的递推公式，计算到时刻t+1部分观测序列为o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t+1</span></small></sub>且在时刻t+1处于状态q<sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>的前向概率，如图10.1所示。在式（10.16）的方括弧里，既然at(j)是到时刻t观测到o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>并在时刻t处于状态q<sub class="calibre8"><small class="calibre6"><span class="calibre7">j</span></small></sub>的前向概率，那么乘积a<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>(j)a<sub class="calibre8"><small class="calibre6"><span class="calibre7">ji</span></small></sub>就是到时刻t观测到o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>并在时刻t处于状态q<sub class="calibre8"><small class="calibre6"><span class="calibre7">j</span></small></sub>而在时刻t+1到达状态q<sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>的联合概率。对这个乘积在时刻t的所有可能的N个状态q<sub class="calibre8"><small class="calibre6"><span class="calibre7">j</span></small></sub>求和，其结果就是到时刻t观测为o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>并在时刻t+1处于状态q<sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>的联合概率。方括弧里的值与观测概率b<sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t+1</span></small></sub>)的乘积恰好是到时刻t+1观测到o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t+1</span></small></sub>并在时刻t+1处于状态q<sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>的前向概率a<sub class="calibre8"><small class="calibre6"><span class="calibre7">t+1</span></small></sub>(i)。步骤（3）给出P(O|<img src="images/00759.jpg" class="calibre_47"/>)的计算公式。因为</p><p class="calibre_20"><img src="images/00591.jpg" class="calibre_785"/></p><p class="calibre_22">所以</p><p class="calibre_20"><img src="images/00734.jpg" class="calibre_786"/></p><p class="calibre_20"><img src="images/00809.jpg" class="calibre_787"/></p><p class="calibre_20"><span class="calibre4">图10.1　前向概率的递推公式</span></p><p class="calibre_27">如图10.2所示，前向算法实际是基于“状态序列的路径结构”递推计算P(O|<img src="images/00759.jpg" class="calibre_47"/>)的算法。前向算法高效的关键是其局部计算前向概率，然后利用路径结构将前向概率“递推”到全局，得到P(O|<img src="images/00759.jpg" class="calibre_47"/>)。具体地，在时刻t＝1，计算a<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>(i)的N个值(i＝1,2,…,N)；在各个时刻t＝1,2,…,T-1，计算a<sub class="calibre8"><small class="calibre6"><span class="calibre7">t+1</span></small></sub>(i)的N个值(i＝1,2,…,N)，而且每个a<sub class="calibre8"><small class="calibre6"><span class="calibre7">t+1</span></small></sub>(i)的计算利用前一时刻N个a<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>(j)。减少计算量的原因在于每一次计算直接引用前一个时刻的计算结果，避免重复计算。这样，利用前向概率计算P(O|<img src="images/00759.jpg" class="calibre_47"/>)的计算量是O(N<sup class="calibre5"><small class="calibre6"><span class="calibre7">2</span></small></sup> T)阶的，而不是直接计算的O(TN<sup class="calibre5"><small class="calibre6"><span class="calibre7">T</span></small></sup>)阶。</p><p class="calibre_20"><img src="images/00914.jpg" class="calibre_788"/></p><p class="calibre_20"><span class="calibre4">图10.2　观测序列路径结构</span></p><p class="calibre_27"><span class="bold">例10.2</span>　考虑盒子和球模型<img src="images/00759.jpg" class="calibre_47"/>＝(A，B,<img src="images/01057.jpg" class="calibre_686"/>)，状态集合Q＝{1,2,3}，观测集合V＝{红，白}，</p><p class="calibre_20"><img src="images/00595.jpg" class="calibre_789"/></p><p class="calibre_24">设T＝3，O＝(红,白,红)，试用前向算法计算P(O|<img src="images/00759.jpg" class="calibre_47"/>)。</p><p class="calibre_8"><span class="bold">解</span>　按照算法10.2</p><p class="calibre_8">（1）计算初值</p><p class="calibre_20"><img src="images/00064.jpg" class="calibre_790"/></p><p class="calibre_24">（2）递推计算</p><p class="calibre_20"><img src="images/00170.jpg" class="calibre_791"/></p><p class="calibre_20"><img src="images/00277.jpg" class="calibre_792"/></p><p class="calibre_24">（3）终止</p><p class="calibre_20"><img src="images/00391.jpg" class="calibre_793"/></p><p id="filepos589327" class="calibre_6"><span class="calibre2"><span class="bold">10.2.3　后向算法</span></span></p><p class="calibre_7"><span class="bold">定义10.3（后向概率）</span>　给定隐马尔可夫模型<img src="images/00759.jpg" class="calibre_47"/>，定义在时刻t状态为q<sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>的条件下，从t+1到T的部分观测序列为o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t+1</span></small></sub>,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t+2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>的概率为后向概率，记作</p><p class="calibre_20"><img src="images/00502.jpg" class="calibre_292"/></p><p class="calibre_24">可以用递推的方法求得后向概率β<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>(i)及观测序列概率P(O|<img src="images/00759.jpg" class="calibre_47"/>)。</p><p class="calibre_146"><span class="bold">算法10.3　（观测序列概率的后向算法）</span></p><p class="calibre_146">输入：隐马尔可夫模型<img src="images/00759.jpg" class="calibre_47"/>，观测序列O；</p><p class="calibre_8">输出：观测序列概率P(O|<img src="images/00759.jpg" class="calibre_47"/>)。</p><p class="calibre_20"><img src="images/00619.jpg" class="calibre_794"/></p><p class="calibre_24">步骤（1）初始化后向概率，对最终时刻的所有状态q<sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>规定β<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>(i)＝1。步骤（2）是后向概率的递推公式。如图10.3所示，为了计算在时刻t状态为q<sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>条件下时刻t+1之后的观测序列为o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t+1</span></small></sub>,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t+2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>的后向概率β<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>(i)，只需考虑在时刻t+1所有</p><p class="calibre_20"><img src="images/00724.jpg" class="calibre_795"/></p><p class="calibre_20"><span class="calibre4">图10.3　后向概率递推公式</span></p><p class="calibre_60">可能的N个状态q<sub class="calibre8"><small class="calibre6"><span class="calibre7">j</span></small></sub>的转移概率（即a<sub class="calibre8"><small class="calibre6"><span class="calibre7">ij</span></small></sub>项），以及在此状态下的观测o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t+1</span></small></sub>的观测概率（即b<sub class="calibre8"><small class="calibre6"><span class="calibre7">j</span></small></sub>(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t+1</span></small></sub>)项），然后考虑状态q<sub class="calibre8"><small class="calibre6"><span class="calibre7">j</span></small></sub>之后的观测序列的后向概率（即β<sub class="calibre8"><small class="calibre6"><span class="calibre7">t+1</span></small></sub>(j)项）。步骤（3）求P(O|<img src="images/00759.jpg" class="calibre_47"/>)的思路与步骤（2）一致，只是初始概率<img src="images/01057.jpg" class="calibre_686"/><sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>代替转移概率。</p><p class="calibre_8">利用前向概率和后向概率的定义可以将观测序列概率P(O|<img src="images/00759.jpg" class="calibre_47"/>)统一写成</p><p class="calibre_20"><img src="images/00836.jpg" class="calibre_796"/></p><p class="calibre_24">此式当t＝1和t＝T-1时分别为式（10.17）和式（10.21）。</p><p id="filepos592871" class="calibre_6"><span class="calibre2"><span class="bold">10.2.4　一些概率与期望值的计算</span></span></p><p class="calibre_7">利用前向概率和后向概率，可以得到关于单个状态和两个状态概率的计算公式。</p><p class="calibre_8">1．给定模型<img src="images/00759.jpg" class="calibre_47"/>和观测O，在时刻t处于状态q<sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>的概率。记</p><p class="calibre_20"><img src="images/00944.jpg" class="calibre_797"/></p><p class="calibre_22">可以通过前向后向概率计算。事实上，</p><p class="calibre_20"><img src="images/01053.jpg" class="calibre_798"/></p><p class="calibre_22">由前向概率a<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>(i)和后向概率β<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>(i)定义可知：</p><p class="calibre_20"><img src="images/00094.jpg" class="calibre_799"/></p><p class="calibre_22">于是得到：</p><p class="calibre_20"><img src="images/00200.jpg" class="calibre_800"/></p><p class="calibre_24">2．给定模型<img src="images/00759.jpg" class="calibre_47"/>和观测O，在时刻t处于状态iq且在时刻1t+处于状态q<sub class="calibre8"><small class="calibre6"><span class="calibre7">j</span></small></sub>的概率。记</p><p class="calibre_20"><img src="images/00918.jpg" class="calibre_801"/></p><p class="calibre_22">可以通过前向后向概率计算：</p><p class="calibre_20"><img src="images/00287.jpg" class="calibre_802"/></p><p class="calibre_22">而</p><p class="calibre_20"><img src="images/00070.jpg" class="calibre_803"/></p><p class="calibre_22">所以</p><p class="calibre_20"><img src="images/00176.jpg" class="calibre_804"/></p><p class="calibre_24">3．将<img src="images/00021.jpg" class="calibre_18"/><sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>(i)和<img src="images/01009.jpg" class="calibre_31"/><sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>(i,j)对各个时刻t求和，可以得到一些有用的期望值：</p><p class="calibre_8">（1）在观测O下状态i出现的期望值</p><p class="calibre_20"><img src="images/00283.jpg" class="calibre_805"/></p><p class="calibre_24">（2）在观测O下由状态i转移的期望值</p><p class="calibre_20"><img src="images/00396.jpg" class="calibre_805"/></p><p class="calibre_24">（3）在观测O下由状态i转移到状态j的期望值</p><p class="calibre_20"><img src="images/00507.jpg" class="calibre_806"/></p><p id="filepos595908" class="calibre_6"><span class="calibre9"><span class="bold">10.3　学习算法</span></span></p><p class="calibre_7">隐马尔可夫模型的学习，根据训练数据是包括观测序列和对应的状态序列还是只有观测序列，可以分别由监督学习与非监督学习实现。本节首先介绍监督学习算法，而后介绍非监督学习算法——Baum-Welch算法（也就是EM算法）。</p><p id="filepos596332" class="calibre_6"><span class="calibre2"><span class="bold">10.3.1　监督学习方法</span></span></p><p class="calibre_7">假设已给训练数据包含S个长度相同的观测序列和对应的状态序列{(O<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>,I<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>),(O<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,I<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>),…,(O<sub class="calibre8"><small class="calibre6"><span class="calibre7">S</span></small></sub>,I<sub class="calibre8"><small class="calibre6"><span class="calibre7">S</span></small></sub>)}，那么可以利用极大似然估计法来估计隐马尔可夫模型的参数。具体方法如下。</p><p class="calibre_8">1．转移概率a<sub class="calibre8"><small class="calibre6"><span class="calibre7">ij</span></small></sub>的估计</p><p class="calibre_8">设样本中时刻t处于状态i时刻t+1转移到状态j的频数为A<sub class="calibre8"><small class="calibre6"><span class="calibre7">ij</span></small></sub>，那么状态转移概率a<sub class="calibre8"><small class="calibre6"><span class="calibre7">ij</span></small></sub>的估计是</p><p class="calibre_20"><img src="images/00623.jpg" class="calibre_807"/></p><p class="calibre_24">2．观测概率b<sub class="calibre8"><small class="calibre6"><span class="calibre7">j</span></small></sub>(k)的估计</p><p class="calibre_8">设样本中状态为j并观测为k的频数是B<sub class="calibre8"><small class="calibre6"><span class="calibre7">jk</span></small></sub>，那么状态为j观测为k的概率b<sub class="calibre8"><small class="calibre6"><span class="calibre7">j</span></small></sub>(k)的估计是</p><p class="calibre_20"><img src="images/00729.jpg" class="calibre_808"/></p><p class="calibre_24">3．初始状态概率<img src="images/01057.jpg" class="calibre_686"/><sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>的估计<img src="images/00080.jpg" class="calibre_586"/><sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>为S个样本中初始状态为q<sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>的频率</p><p class="calibre_8">由于监督学习需要使用训练数据，而人工标注训练数据往往代价很高，有时就会利用非监督学习的方法。</p><p id="filepos598452" class="calibre_6"><span class="calibre2"><span class="bold">10.3.2　Baum-Welch算法</span></span></p><p class="calibre_7">假设给定训练数据只包含S个长度为T的观测序列{O<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>,O<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,O<sub class="calibre8"><small class="calibre6"><span class="calibre7">S</span></small></sub>}而没有对应的状态序列，目标是学习隐马尔可夫模型<img src="images/00759.jpg" class="calibre_47"/>＝(A，B,<img src="images/01057.jpg" class="calibre_686"/>)的参数。我们将观测序列数据看作观测数据O，状态序列数据看作不可观测的隐数据I，那么隐马尔可夫模型事实上是一个含有隐变量的概率模型</p><p class="calibre_20"><img src="images/00839.jpg" class="calibre_809"/></p><p class="calibre_22">它的参数学习可以由EM算法实现。</p><p class="calibre_8">1．确定完全数据的对数似然函数</p><p class="calibre_8">所有观测数据写成O＝(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)，所有隐数据写成I＝(i<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，i<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,i<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)，完全数据是(O,I)＝(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>,i<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，i<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,i<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)。完全数据的对数似然函数是logP(O，I|<img src="images/00759.jpg" class="calibre_47"/>)。</p><p class="calibre_8">2．EM算法的E步：求Q函数(<img src="images/00759.jpg" class="calibre_47"/>,<img src="images/00948.jpg" class="calibre_810"/>)<sup class="calibre5"><small id="filepos600545" class="calibre6"><a href="#filepos627506"><span class="calibre7">[1]</span></a></small></sup></p><p class="calibre_20"><img src="images/01058.jpg" class="calibre_811"/></p><p class="calibre_22">其中，<img src="images/00948.jpg" class="calibre_810"/>是隐马尔可夫模型参数的当前估计值，<img src="images/00759.jpg" class="calibre_47"/>是要极大化的隐马尔可夫模型参数。</p><p class="calibre_20"><img src="images/00098.jpg" class="calibre_812"/></p><p class="calibre_22">于是函数Q(<img src="images/00759.jpg" class="calibre_47"/>,<img src="images/00948.jpg" class="calibre_810"/>)可以写成：</p><p class="calibre_20"><img src="images/00203.jpg" class="calibre_813"/></p><p class="calibre_22">式中求和都是对所有训练数据的序列总长度T进行的。</p><p class="calibre_8">3．EM算法的M步：极大化Q函数Q(<img src="images/00759.jpg" class="calibre_47"/>,<img src="images/00948.jpg" class="calibre_810"/>)求模型参数A,B,<img src="images/01057.jpg" class="calibre_686"/></p><p class="calibre_8">由于要极大化的参数在式（10.34）中单独地出现在3个项中，所以只需对各项分别极大化。</p><p class="calibre_8">（1）式（10.34）的第1项可以写成：</p><p class="calibre_20"><img src="images/00311.jpg" class="calibre_814"/></p><p class="calibre_22">注意到<img src="images/01057.jpg" class="calibre_686"/><sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>满足约束条件<img src="images/00424.jpg" class="calibre_815"/>，利用拉格朗日乘子法，写出拉格朗日函数：</p><p class="calibre_20"><img src="images/00538.jpg" class="calibre_816"/></p><p class="calibre_22">对其求偏导数并令结果为0</p><p class="calibre_20"><img src="images/00519.jpg" class="calibre_817"/></p><p class="calibre_22">得</p><p class="calibre_20"><img src="images/00757.jpg" class="calibre_818"/></p><p class="calibre_22">对i求和得到<img src="images/00021.jpg" class="calibre_18"/></p><p class="calibre_20"><img src="images/00548.jpg" class="calibre_819"/></p><p class="calibre_22">代入式（10.35）即得</p><p class="calibre_20"><img src="images/00974.jpg" class="calibre_820"/></p><p class="calibre_24">（2）式（10.34）的第2项可以写成</p><p class="calibre_20"><img src="images/00013.jpg" class="calibre_821"/></p><p class="calibre_22">类似第1项，应用具有约束条件<img src="images/00055.jpg" class="calibre_822"/>的拉格朗日乘子法可以求出</p><p class="calibre_20"><img src="images/00231.jpg" class="calibre_823"/></p><p class="calibre_22">（3）式（10.34）的第3项为</p><p class="calibre_20"><img src="images/00340.jpg" class="calibre_824"/></p><p class="calibre_22">同样用拉格朗日乘子法，约束条件是<img src="images/00322.jpg" class="calibre_539"/>。注意，只有在o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>＝v<sub class="calibre8"><small class="calibre6"><span class="calibre7">k</span></small></sub>时b<sub class="calibre8"><small class="calibre6"><span class="calibre7">j</span></small></sub>(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>)对b<sub class="calibre8"><small class="calibre6"><span class="calibre7">j</span></small></sub>(k)的偏导数才不为0，以I(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>＝v<sub class="calibre8"><small class="calibre6"><span class="calibre7">k</span></small></sub>)表示。求得</p><p class="calibre_20"><img src="images/00568.jpg" class="calibre_825"/></p><p id="filepos604686" class="calibre_6"><span class="calibre2"><span class="bold">10.3.3　Baum-Welch模型参数估计公式</span></span></p><p class="calibre_7">将式（10.36）～式（10.38）中的各概率分别用<img src="images/00021.jpg" class="calibre_18"/><sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>(i)，<img src="images/01009.jpg" class="calibre_31"/><sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>(i,j)表示，则可将相应的公式写成：</p><p class="calibre_20"><img src="images/00679.jpg" class="calibre_826"/></p><p class="calibre_22">其中，<img src="images/00021.jpg" class="calibre_18"/><sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>(i)，<img src="images/01009.jpg" class="calibre_31"/><sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>(i,j)分别由式（10.24）及式（10.26）给出。式（10.39）～式（10.41）就是Baum-Welch算法（Baum-Welch algorithm），它是EM算法在隐马尔可夫模型学习中的具体实现，由Baum和Welch提出。</p><p class="calibre_146"><span class="bold">算法10.4（Baum-Welch算法）</span></p><p class="calibre_146">输入：观测数据O＝(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)；</p><p class="calibre_8">输出：隐马尔可夫模型参数。</p><p class="calibre_8">（1）初始化</p><p class="calibre_8">对n＝0，选取<img src="images/00788.jpg" class="calibre_827"/>，<img src="images/00892.jpg" class="calibre_828"/>，<img src="images/01002.jpg" class="calibre_827"/>，得到模型<img src="images/00759.jpg" class="calibre_47"/><sup class="calibre5"><small class="calibre6"><span class="calibre7">(0)</span></small></sup>＝(A<sup class="calibre5"><small class="calibre6"><span class="calibre7">(0)</span></small></sup>,B<sup class="calibre5"><small class="calibre6"><span class="calibre7">(0)</span></small></sup>,<img src="images/01057.jpg" class="calibre_686"/><sup class="calibre5"><small class="calibre6"><span class="calibre7">(0)</span></small></sup>)。</p><p class="calibre_8">（2）递推。对n＝1,2,…，</p><p class="calibre_20"><img src="images/00495.jpg" class="calibre_829"/></p><p class="calibre_20"><img src="images/00155.jpg" class="calibre_830"/></p><p class="calibre_22">右端各值按观测O＝(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)和模型<img src="images/00759.jpg" class="calibre_47"/><sup class="calibre5"><small class="calibre6"><span class="calibre7">(n)</span></small></sup>＝(A<sup class="calibre5"><small class="calibre6"><span class="calibre7">(n)</span></small></sup>,B<sup class="calibre5"><small class="calibre6"><span class="calibre7">(n)</span></small></sup>,<img src="images/01057.jpg" class="calibre_686"/><sup class="calibre5"><small class="calibre6"><span class="calibre7">(n)</span></small></sup>)计算。式中<img src="images/00021.jpg" class="calibre_18"/><sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>(i)，<img src="images/01009.jpg" class="calibre_31"/><sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>(i,j)由式（10.24）和式（10.26）给出。</p><p class="calibre_8">（3）终止。得到模型参数<img src="images/00759.jpg" class="calibre_47"/><sup class="calibre5"><small class="calibre6"><span class="calibre7">(N+1)</span></small></sup>＝(A<sup class="calibre5"><small class="calibre6"><span class="calibre7">(N+1)</span></small></sup>,B<sup class="calibre5"><small class="calibre6"><span class="calibre7">(N+1)</span></small></sup>,<img src="images/01057.jpg" class="calibre_686"/><sup class="calibre5"><small class="calibre6"><span class="calibre7">(N+1)</span></small></sup>)。</p><p id="filepos608414" class="calibre_6"><span class="calibre9"><span class="bold">10.4　预测算法</span></span></p><p class="calibre_7">下面介绍隐马尔可夫模型预测的两种算法：近似算法与维特比算法（Viterbi algorithm）。</p><p id="filepos608654" class="calibre_6"><span class="calibre2"><span class="bold">10.4.1　近似算法</span></span></p><p class="calibre_7">近似算法的想法是，在每个时刻t选择在该时刻最有可能出现的状态<img src="images/00746.jpg" class="calibre_831"/>，从而得到一个状态序列I<sup class="calibre5"><small class="calibre6"><span class="calibre7">*</span></small></sup>＝(<img src="images/00222.jpg" class="calibre_832"/>，<img src="images/00773.jpg" class="calibre_833"/>,…,<img src="images/00677.jpg" class="calibre_833"/>)，将它作为预测的结果。</p><p class="calibre_8">给定隐马尔可夫模型<img src="images/00759.jpg" class="calibre_47"/>和观测序列O，在时刻t处于状态q<sub class="calibre8"><small class="calibre6"><span class="calibre7">i</span></small></sub>的概率<img src="images/00021.jpg" class="calibre_18"/><sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>(i)是</p><p class="calibre_20"><img src="images/00785.jpg" class="calibre_834"/></p><p class="calibre_22">在每一时刻t最有可能的状态<img src="images/00746.jpg" class="calibre_831"/>是</p><p class="calibre_20"><img src="images/00685.jpg" class="calibre_835"/></p><p class="calibre_22">从而得到状态序列I<sup class="calibre5"><small class="calibre6"><span class="calibre7">*</span></small></sup>＝(<img src="images/00222.jpg" class="calibre_832"/>，<img src="images/00773.jpg" class="calibre_833"/>,…,<img src="images/00677.jpg" class="calibre_833"/>)。</p><p class="calibre_8">近似算法的优点是计算简单，其缺点是不能保证预测的状态序列整体是最有可能的状态序列，因为预测的状态序列可能有实际不发生的部分。事实上，上述方法得到的状态序列中有可能存在转移概率为0的相邻状态，即对某些i,j，a<sub class="calibre8"><small class="calibre6"><span class="calibre7">ij</span></small></sub>＝0时。尽管如此，近似算法仍然是有用的。</p><p id="filepos610742" class="calibre_6"><span class="calibre2"><span class="bold">10.4.2　维特比算法</span></span></p><p class="calibre_7">维特比算法实际是用动态规划解隐马尔可夫模型预测问题，即用动态规划（dynamic programming）求概率最大路径（最优路径）。这时一条路径对应着一个状态序列。</p><p class="calibre_8">根据动态规划原理，最优路径具有这样的特性：如果最优路径在时刻t通过结点<img src="images/00746.jpg" class="calibre_831"/>，那么这一路径从结点<img src="images/00746.jpg" class="calibre_831"/>到终点<img src="images/00677.jpg" class="calibre_833"/>的部分路径，对于从<img src="images/00746.jpg" class="calibre_831"/>到<img src="images/00677.jpg" class="calibre_833"/>的所有可能的部分路径来说，必须是最优的。因为假如不是这样，那么从<img src="images/00746.jpg" class="calibre_831"/>到<img src="images/00677.jpg" class="calibre_833"/>就有另一条更好的部分路径存在，如果把它和从<img src="images/00222.jpg" class="calibre_832"/>到达<img src="images/00746.jpg" class="calibre_831"/>的部分路径连接起来，就会形成一条比原来的路径更优的路径，这是矛盾的。依据这一原理，我们只需从时刻t＝1开始，递推地计算在时刻t状态为i的各条部分路径的最大概率，直至得到时刻t＝T状态为i的各条路径的最大概率。时刻t＝T的最大概率即为最优路径的概率P<sup class="calibre5"><small class="calibre6"><span class="calibre7">*</span></small></sup>，最优路径的终结点<img src="images/00677.jpg" class="calibre_833"/>也同时得到。之后，为了找出最优路径的各个结点，从终结点<img src="images/00677.jpg" class="calibre_833"/>开始，由后向前逐步求得结点<img src="images/00999.jpg" class="calibre_836"/>,…,<img src="images/00222.jpg" class="calibre_832"/>，得到最优路径I<sup class="calibre5"><small class="calibre6"><span class="calibre7">*</span></small></sup>＝(<img src="images/00222.jpg" class="calibre_832"/>，<img src="images/00773.jpg" class="calibre_833"/>,…,<img src="images/00677.jpg" class="calibre_833"/>)。这就是维特比算法。</p><p class="calibre_8">首先导入两个变量<img src="images/00850.jpg" class="calibre_73"/>和Ψ。定义在时刻t状态为i的所有单个路径(i<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，i<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,i<sub class="calibre8"><small class="calibre6"><span class="calibre7">t</span></small></sub>)中概率最大值为</p><p class="calibre_20"><img src="images/00042.jpg" class="calibre_837"/></p><p class="calibre_24">由定义可得变量<img src="images/00850.jpg" class="calibre_73"/>的递推公式：</p><p class="calibre_20"><img src="images/00146.jpg" class="calibre_838"/></p><p class="calibre_24">定义在时刻t状态为i的所有单个路径(i<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，i<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,i<sub class="calibre8"><small class="calibre6"><span class="calibre7">t-1</span></small></sub>,i)中概率最大的路径的第t-1个结点为</p><p class="calibre_20"><img src="images/00258.jpg" class="calibre_839"/></p><p class="calibre_24">下面介绍维特比算法。</p><p class="calibre_146"><span class="bold">算法10.5（维特比算法）</span></p><p class="calibre_146">输入：模型<img src="images/00759.jpg" class="calibre_47"/>＝(A，B,<img src="images/01057.jpg" class="calibre_686"/>)和观测O＝(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)；</p><p class="calibre_8">输出：最优路径I<sup class="calibre5"><small class="calibre6"><span class="calibre7">*</span></small></sup>＝(<img src="images/00222.jpg" class="calibre_832"/>，<img src="images/00773.jpg" class="calibre_833"/>,…,<img src="images/00677.jpg" class="calibre_833"/>)。</p><p class="calibre_8">（1）初始化</p><p class="calibre_20"><img src="images/00213.jpg" class="calibre_840"/></p><p class="calibre_24">（2）递推。对t＝2,3,…,T</p><p class="calibre_20"><img src="images/00735.jpg" class="calibre_841"/></p><p class="calibre_24">（3）终止</p><p class="calibre_20"><img src="images/00257.jpg" class="calibre_842"/></p><p class="calibre_24">（4）最优路径回溯。对t＝T-1,T-2,…,1</p><p class="calibre_20"><img src="images/00796.jpg" class="calibre_843"/></p><p class="calibre_22">求得最优路径I<sup class="calibre5"><small class="calibre6"><span class="calibre7">*</span></small></sup>＝(<img src="images/00222.jpg" class="calibre_832"/>，<img src="images/00773.jpg" class="calibre_833"/>,…,<img src="images/00677.jpg" class="calibre_833"/>)。</p><p class="calibre_8">下面通过一个例子来说明维特比算法。</p><p class="calibre_8"><span class="bold">例10.3</span>　例10.2的模型<img src="images/00759.jpg" class="calibre_47"/>＝(A，B,<img src="images/01057.jpg" class="calibre_686"/>)，</p><p class="calibre_20"><img src="images/00813.jpg" class="calibre_844"/></p><p class="calibre_22">已知观测序列O＝(红,白,红)，试求最优状态序列，即最优路径I<sup class="calibre5"><small class="calibre6"><span class="calibre7">*</span></small></sup>＝(<img src="images/00222.jpg" class="calibre_832"/>，<img src="images/00773.jpg" class="calibre_833"/>，<img src="images/00919.jpg" class="calibre_833"/>)。</p><p class="calibre_8"><span class="bold">解</span>　如图10.4所示，要在所有可能的路径中选择一条最优路径，按照以下步骤处理：</p><p class="calibre_20"><img src="images/00552.jpg" class="calibre_845"/></p><p class="calibre_20"><span class="calibre4">图10.4　求最优路径</span></p><p class="calibre_27">（1）初始化。在t＝1时，对每一个状态i，i＝1,2,3，求状态为i观测o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>为红的概率，记此概率为<img src="images/00850.jpg" class="calibre_73"/><sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>(i)，则</p><p class="calibre_20"><img src="images/00421.jpg" class="calibre_846"/></p><p class="calibre_22">代入实际数据</p><p class="calibre_20"><img src="images/00324.jpg" class="calibre_847"/></p><p class="calibre_22">记Ψ<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>(i)＝0，i＝1,2,3。</p><p class="calibre_8">（2）在t＝2时，对每个状态i，i＝1,2,3，求在t＝1时状态为j观测为红并在t＝2时状态为i观测o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>为白的路径的最大概率，记此最大概率为<img src="images/00850.jpg" class="calibre_73"/><sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>(i)，则</p><p class="calibre_20"><img src="images/00875.jpg" class="calibre_848"/></p><p class="calibre_22">同时，对每个状态i，i＝1,2,3，记录概率最大路径的前一个状态j：</p><p class="calibre_20"><img src="images/00350.jpg" class="calibre_849"/></p><p class="calibre_22">计算：</p><p class="calibre_20"><img src="images/00903.jpg" class="calibre_850"/></p><p class="calibre_22">同样，在t＝3时，</p><p class="calibre_20"><img src="images/00970.jpg" class="calibre_851"/></p><p class="calibre_24">（3）以P<sup class="calibre5"><small class="calibre6"><span class="calibre7">*</span></small></sup>表示最优路径的概率，则</p><p class="calibre_20"><img src="images/00504.jpg" class="calibre_852"/></p><p class="calibre_22">最优路径的终点是<img src="images/00919.jpg" class="calibre_833"/>：</p><p class="calibre_20"><img src="images/00840.jpg" class="calibre_853"/></p><p class="calibre_24">（4）由最优路径的终点<img src="images/00919.jpg" class="calibre_833"/>，逆向找到<img src="images/00773.jpg" class="calibre_833"/>,<img src="images/00222.jpg" class="calibre_832"/>：</p><p class="calibre_20"><img src="images/00662.jpg" class="calibre_854"/></p><p class="calibre_24">于是求得最优路径，即最优状态序列I<sup class="calibre5"><small class="calibre6"><span class="calibre7">*</span></small></sup>＝(<img src="images/00222.jpg" class="calibre_832"/>,<img src="images/00773.jpg" class="calibre_833"/>,<img src="images/00919.jpg" class="calibre_833"/>)＝(3,3,3)。</p><p id="filepos620284" class="calibre_6"><span class="calibre9"><span class="bold">本章概要</span></span></p><p class="calibre_7">1．隐马尔可夫模型是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的状态的序列，再由各个状态随机生成一个观测而产生观测的序列的过程。</p><p class="calibre_8">隐马尔可夫模型由初始状态概率向量<img src="images/01057.jpg" class="calibre_686"/>、状态转移概率矩阵A和观测概率矩阵B决定。因此，隐马尔可夫模型可以写成<img src="images/00759.jpg" class="calibre_47"/>＝(A，B,<img src="images/01057.jpg" class="calibre_686"/>)。</p><p class="calibre_8">隐马尔可夫模型是一个生成模型，表示状态序列和观测序列的联合分布，但是状态序列是隐藏的，不可观测的。</p><p class="calibre_8">隐马尔可夫模型可以用于标注，这时状态对应着标记。标注问题是给定观测序列预测其对应的标记序列。</p><p class="calibre_8">2．概率计算问题。给定模型<img src="images/00759.jpg" class="calibre_47"/>＝(A，B,<img src="images/01057.jpg" class="calibre_686"/>)和观测序列O＝(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)，计算在模型<img src="images/00759.jpg" class="calibre_47"/>下观测序列O出现的概率P(O|<img src="images/00759.jpg" class="calibre_47"/>)。前向-后向算法是通过递推地计算前向-后向概率可以高效地进行隐马尔可夫模型的概率计算。</p><p class="calibre_8">3．学习问题。已知观测序列O＝(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)，估计模型<img src="images/00759.jpg" class="calibre_47"/>＝(A，B,<img src="images/01057.jpg" class="calibre_686"/>)参数，使得在该模型下观测序列概率P(O|<img src="images/00759.jpg" class="calibre_47"/>)最大。即用极大似然估计的方法估计参数。Baum-Welch算法，也就是EM算法可以高效地对隐马尔可夫模型进行训练。它是一种非监督学习算法。</p><p class="calibre_8">4．预测问题。已知模型<img src="images/00759.jpg" class="calibre_47"/>＝(A，B,<img src="images/01057.jpg" class="calibre_686"/>)和观测序列O＝(o<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，o<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,o<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)，求对给定观测序列条件概率P(I|O)最大的状态序列I＝(i<sub class="calibre8"><small class="calibre6"><span class="calibre7">1</span></small></sub>，i<sub class="calibre8"><small class="calibre6"><span class="calibre7">2</span></small></sub>,…,i<sub class="calibre8"><small class="calibre6"><span class="calibre7">T</span></small></sub>)。维特比算法应用动态规划高效地求解最优路径，即概率最大的状态序列。</p><p id="filepos623475" class="calibre_6"><span class="calibre9"><span class="bold">继续阅读</span></span></p><p class="calibre_7">隐马尔可夫模型的介绍可见文献[1,2]，特别地，文献[1]是经典的介绍性论文。关于Baum-Welch算法可见文献[3,4]。可以认为概率上下文无关文法（probabilistic context-free grammar）是隐马尔可夫模型的一种推广，隐马尔可夫模型的不可观测数据是状态序列，而概率上下文无关文法的不可观测数据是上下文无关文法树[5]。动态贝叶斯网络（dynamic Bayesian network）是定义在时序数据上的贝叶斯网络,它包含隐马尔可夫模型，是一种特例<sup class="calibre5"><small class="calibre6"><span class="calibre7">[6]</span></small></sup>。</p><p id="filepos624202" class="calibre_6"><span class="calibre9"><span class="bold">习题</span></span></p><p class="calibre_7">10.1　给定盒子和球组成的隐马尔可夫模型<img src="images/00759.jpg" class="calibre_47"/>＝(A,B,<img src="images/01057.jpg" class="calibre_686"/>)，其中，</p><p class="calibre_20"><img src="images/00183.jpg" class="calibre_855"/></p><p class="calibre_24">设T＝4，O＝(红,白,红,白)，试用后向算法计算P(O|<img src="images/00759.jpg" class="calibre_47"/>)。</p><p class="calibre_8">10.2　考虑盒子和球组成的隐马尔可夫模型<img src="images/00759.jpg" class="calibre_47"/>＝(A,B,<img src="images/01057.jpg" class="calibre_686"/>)，其中，</p><p class="calibre_20"><img src="images/00988.jpg" class="calibre_856"/></p><p class="calibre_24">设T＝8，O＝(红,白,红,红,白,红,白,白)，用前向后向概率计算P(i<sub class="calibre8"><small class="calibre6"><span class="calibre7">4</span></small></sub>＝q<sub class="calibre8"><small class="calibre6"><span class="calibre7">3</span></small></sub>|O,<img src="images/00759.jpg" class="calibre_47"/>)。</p><p class="calibre_8">10.3　在习题10.1中，试用维特比算法求最优路径I<sup class="calibre5"><small class="calibre6"><span class="calibre7">*</span></small></sup>＝(<img src="images/00222.jpg" class="calibre_832"/>，<img src="images/00773.jpg" class="calibre_833"/>，<img src="images/00919.jpg" class="calibre_833"/>，<img src="images/00464.jpg" class="calibre_832"/>)。</p><p class="calibre_8">10.4　试用前向概率和后向概率推导</p><p class="calibre_20"><img src="images/00313.jpg" class="calibre_857"/></p><p class="calibre_24">10.5　比较维特比算法中变量<img src="images/00850.jpg" class="calibre_73"/>的计算和前向算法中变量a的计算的主要区别。</p><p id="filepos626264" class="calibre_6"><span class="calibre9"><span class="bold">参考文献</span></span></p><p class="calibre_7">[1]　Rabiner L,Juang B. An introduction to hidden markov Models. IEEE ASSP Magazine,January 1986</p><p class="calibre_8">[2]　Rabiner L. A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of IEEE,1989</p><p class="calibre_8">[3]　Baum L,et al. A maximization technique occuring in the statistical analysis of probabilistic functions of Markov chains. Annals of Mathematical Statistics,1970,41: 164–171</p><p class="calibre_8">[4]　Bilmes JA. A gentle tutorial of the EM algorithm and its application to parameter estimation for Gaussian mixture and hidden Markov models. http://ssli.ee.washington.edu/~bilmes/mypubs/ bilmes1997-em.pdf</p><p class="calibre_8">[5]　Lari K,Young SJ. Applications of stochastic context-free grammars using the Inside-Outside algorithm,Computer Speech &amp; Language,1991,5(3): 237–257</p><p class="calibre_8">[6]　Ghahramani Z. Learning Dynamic Bayesian Networks. Lecture Notes in Computer Science,Vol. 1387,1997,168–197</p><p class="calibre_98"><span class="calibre2"><span class="bold">注释</span></span></p><p id="filepos627506" class="calibre_99"><a href="#filepos600545"><span class="calibre4">[1]</span></a><span class="calibre4">　按照Q函数的定义</span></p><p class="calibre_33"><span class="calibre4">Q(</span><img src="images/00759.jpg" class="calibre_47"/><span class="calibre4">,</span><img src="images/00948.jpg" class="calibre_810"/><span class="calibre4">)＝E<sub class="calibre11"><small class="calibre6"><span class="calibre7">I</span></small></sub>[logP(O，I|</span><img src="images/00759.jpg" class="calibre_47"/><span class="calibre4">)|O,</span><img src="images/00948.jpg" class="calibre_810"/><span class="calibre4"> ]</span></p><p class="calibre_8"><span class="calibre4">式（10.33）略去了对</span><img src="images/00759.jpg" class="calibre_47"/><span class="calibre4">而言的常数因子1/P(O|</span><img src="images/00948.jpg" class="calibre_810"/><span class="calibre4">)。</span></p><div class="mbp_pagebreak" id="calibre_pb_15"></div>
</body></html>
